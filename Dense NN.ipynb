{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56cbf943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9e9ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  11 of 11 completed\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8304 entries, 0 to 8303\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype              \n",
      "---  ------          --------------  -----              \n",
      " 0   Date            8304 non-null   datetime64[ns, UTC]\n",
      " 1   ticker          8304 non-null   object             \n",
      " 2   value           8304 non-null   float64            \n",
      " 3   log_diff        8304 non-null   float64            \n",
      " 4   moving_avg      8304 non-null   float64            \n",
      " 5   sig_delta_up    8304 non-null   int64              \n",
      " 6   sig_delta_down  8304 non-null   int64              \n",
      " 7   is_train        8304 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), float64(3), int64(3), object(1)\n",
      "memory usage: 519.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data = yf.download(\"GOOG AAPL MSFT POLX.L POW.L AMD TSLA F KR UMC GM\", start=\"2020-01-01\", end=\"2023-01-01\", group_by=\"ticker\")\n",
    "\n",
    "# Reshape data\n",
    "data = data.unstack().reset_index().rename(columns={\"level_0\": \"ticker\", \"level_1\": \"measure\", 0: \"value\"}).dropna()\n",
    "\n",
    "# Filter to adj close\n",
    "data = data.loc[data[\"measure\"]==\"Adj Close\", [\"Date\", \"ticker\", \"value\"]].reset_index(drop=True)\n",
    "\n",
    "# Calculate log diff\n",
    "data[\"log_diff\"] = data.groupby(\"ticker\")[\"value\"].transform(lambda x: np.log(x) - np.log(x.shift()))\n",
    "\n",
    "# Moving average\n",
    "data[\"moving_avg\"] = data[\"value\"].rolling(5).mean()\n",
    "\n",
    "# Add flag for whether the value is up in the next weeks moving average is up 10 % or down 10%\n",
    "data[\"sig_delta_up\"] = data.groupby(\"ticker\")[\"value\"].transform(lambda x: np.where(((x.shift(-5) - x) / x) > 0.1, 1, 0))\n",
    "data[\"sig_delta_down\"] = data.groupby(\"ticker\")[\"value\"].transform(lambda x: np.where(((x.shift(-5) - x) / x) < -0.1, 1, 0))\n",
    "\n",
    "# Remove nas and reset the index\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb0f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "data[\"scaled_ld\"] = None\n",
    "for ticker in data[\"ticker\"].unique():\n",
    "    scalers[ticker] = MinMaxScaler((-1, 1)).fit(data[(data[\"ticker\"]==ticker) & (data[\"is_train\"]==1)][\"log_diff\"].values.reshape(-1, 1))\n",
    "    data.loc[data[\"ticker\"]==ticker, \"scaled_ld\"] = scalers[ticker].transform(data[data[\"ticker\"]==ticker][\"log_diff\"].values.reshape(-1, 1)).reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a85d8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 10\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "idx = []\n",
    "for ticker in data[\"ticker\"].unique():\n",
    "    ticker_data = data[data[\"ticker\"]==ticker]\n",
    "    length = len(ticker_data[\"scaled_ld\"]) - 1\n",
    "    start, end = ticker_data.index[lookback], ticker_data.index[length]\n",
    "    i = 0\n",
    "    for n in range(lookback-1, length):\n",
    "        x = data[\"scaled_ld\"].values[n-lookback:n]\n",
    "        if len(x) == lookback:\n",
    "            idx.append(i)\n",
    "            i+=1\n",
    "            X.append(x)\n",
    "            y.append(data.loc[n, [\"sig_delta_up\", \"sig_delta_down\"]].values)\n",
    "X = np.array(X).astype(\"float32\")\n",
    "y = np.array(y).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab78745",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = data.loc[idx, \"Date\"][data[\"Date\"] < data[\"Date\"].max() - dt.timedelta(days=60)].index\n",
    "val_idx = data.iloc[~train_idx].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d88098e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8293 is out of bounds for axis 0 with size 8183",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_test, X_train, y_test, y_train \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m train_test_split(train_idx, train_idx, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)]\n\u001b[0;32m----> 3\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m, y[val_idx]\n\u001b[1;32m      5\u001b[0m X_train\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape, X_val\u001b[38;5;241m.\u001b[39mshape, y_val\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8293 is out of bounds for axis 0 with size 8183"
     ]
    }
   ],
   "source": [
    "X_test, X_train, y_test, y_train = [torch.tensor(x) for x in train_test_split(train_idx, train_idx, test_size=0.8, shuffle=True, random_state=2)]\n",
    "\n",
    "X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383c0d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.8, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=500, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.8, inplace=False)\n",
       "    (6): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.8, inplace=False)\n",
       "    (9): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.8, inplace=False)\n",
       "    (12): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Dropout(p=0.8, inplace=False)\n",
       "    (15): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (16): ReLU()\n",
       "    (17): Dropout(p=0.8, inplace=False)\n",
       "    (18): Linear(in_features=500, out_features=100, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Dropout(p=0.8, inplace=False)\n",
       "    (21): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (22): ReLU()\n",
       "    (23): Dropout(p=0.8, inplace=False)\n",
       "    (24): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(10, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(100, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(500, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Linear(100, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.8),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70aae659",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(),  lr=0.001, momentum=0.9)\n",
    "\n",
    "def train(X, y, model, size=None, batch_size=3000):\n",
    "    # X is a torch Variable\n",
    "    permutation = torch.randperm(X.size()[0])\n",
    "\n",
    "    for i in range(0,X.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = X[indices], y[indices]\n",
    "        \n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = model.forward(batch_x)\n",
    "        loss = loss_fn(outputs, batch_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss, current = loss.item(), i * len(X)\n",
    "    return loss\n",
    "\n",
    "def test(X, y, model):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            pred = model(X[i])\n",
    "            test_loss += loss_fn(pred, y[i]).item()\n",
    "            correct += (pred.round() == y[i]).type(torch.float).sum().item()\n",
    "#             if i == 1:\n",
    "#                 print(pred.round(), y[i])\n",
    "    test_loss /= len(X)\n",
    "    correct /= y.numel()\n",
    "    return (100*correct), test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a9f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-------------0\n",
      "loss: 0.277211\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 0.256931 \n",
      "\n",
      "Epoch-------------50\n",
      "loss: 0.250000\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.250000 \n",
      "\n",
      "Epoch-------------100\n",
      "loss: 0.250000\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.250000 \n",
      "\n",
      "Epoch-------------150\n",
      "loss: 0.250000\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.250000 \n",
      "\n",
      "Epoch-------------200\n",
      "loss: 0.250000\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.250000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(201):\n",
    "    loss = train(X_train, y_train, net, len(X_train))\n",
    "    accuracy, test_loss = test(X_test, y_test, net)\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch-------------{epoch}\")\n",
    "        print(f\"loss: {loss:>7f}\")\n",
    "        print(f\"Test Error: \\n Accuracy: {accuracy:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
